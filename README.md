# ollama-chat-ui

Allow users to chat with ML models using a web interface, using the Ollama Chat API.
All the conversations are stored in a database locally in the browser using IndexedDB.

## Run the project

Run in the terminal:

```
docker-compose up
```

## Install a new library

```
docker-compose exec web npm install new-library
```

## Credits

Author: Roberto Silva Z.
