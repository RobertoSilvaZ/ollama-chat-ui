# ollama-chat-ui

Allow users to chat with ML models using a web interface, using the Ollama Chat API.
All the conversations are stored in a database locally in the browser using IndexedDB.

## Run the project

1.  Install the dependencies:

    ```bash
    npm install
    ```

2.  Build the container:

    ```bash
    docker-compose build
    ```

3.  Up the container:
    ```bash
    docker-compose up
    ```

## Credits

Author: Roberto Silva Z.
